### 1.	Что описывает и показывает Big O нотация как высчитывается , что фактически измеряется, привести примеры
**Big O нотация** — это математическая концепция, используемая в информатике для описания **асимптотической сложности алгоритмов**. Она показывает, как время выполнения алгоритма или потребление памяти **растут** с увеличением размера входных данных (обозначаемого как `n`). Big O фокусируется на **наихудшем сценарии** и игнорирует константы и менее значимые члены, оставляя только доминирующую функцию.

---

### **Как вычисляется Big O:**
1. **Определите базовые операции** (например, сравнения, циклы, присваивания).  
2. **Выразите их количество** в зависимости от `n`.  
3. **Упростите выражение**, оставив только самый быстрорастущий член.  
   - Константы игнорируются: `O(5n) → O(n)`.  
   - Младшие степени игнорируются: `O(n² + 3n) → O(n²)`.  

---

### **Что измеряет Big O:**
- **Временная сложность** — количество операций в зависимости от `n`.  
- **Пространственная сложность** — объем используемой памяти в зависимости от `n`.  

---

### **Примеры на Java**

#### **1. O(1) — Константная сложность**  
Доступ к элементу массива по индексу:  
```java
int[] arr = {1, 2, 3, 4, 5};
int x = arr[2]; // Всегда 1 операция, независимо от размера массива.
```

#### **2. O(n) — Линейная сложность**  
Линейный поиск в массиве:  
```java
int findElement(int[] arr, int target) {
    for (int num : arr) { // n итераций
        if (num == target) return num;
    }
    return -1;
}
```

#### **3. O(n²) — Квадратичная сложность**  
Сортировка пузырьком:  
```java
void bubbleSort(int[] arr) {
    for (int i = 0; i < arr.length; i++) { // n итераций
        for (int j = 0; j < arr.length - 1; j++) { // n итераций
            if (arr[j] > arr[j + 1]) {
                // swap
            }
        }
    }
}
```

#### **4. O(log n) — Логарифмическая сложность**  
Бинарный поиск:  
```java
int binarySearch(int[] arr, int target) {
    int left = 0, right = arr.length - 1;
    while (left <= right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] == target) return mid;
        if (arr[mid] < target) left = mid + 1;
        else right = mid - 1;
        // На каждом шаге массив уменьшается вдвое.
    }
    return -1;
}
```

#### **5. O(2ⁿ) — Экспоненциальная сложность**  
Рекурсивное вычисление чисел Фибоначчи:  
```java
int fibonacci(int n) {
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2); // Два рекурсивных вызова на каждом шаге.
}
```

---

### **Иерархия сложностей (от лучшей к худшей):**  
1. **O(1)** — Константная  
2. **O(log n)** — Логарифмическая  
3. **O(n)** — Линейная  
4. **O(n log n)** — Линейно-логарифмическая  
5. **O(n²)** — Квадратичная  
6. **O(2ⁿ)** — Экспоненциальная  

---

### **Почему константы не важны?**  
При больших `n` вклад констант и младших членов становится незначительным. Например, для `n = 1000`:  
- `O(1000n) = 1,000,000` операций.  
- `O(n²) = 1,000,000` операций.  
Но при `n = 10,000`:  
- `O(1000n) = 10,000,000`.  
- `O(n²) = 100,000,000` (растет значительно быстрее).  

---

Big O помогает выбирать оптимальные алгоритмы для больших данных, оценивая их эффективность в теории.

---
---
### 2.	Основные алгоритмы сортировки знать/поимать принцип работы
Основные алгоритмы сортировки в Java: принципы работы и реализация.

---

### 1. **Пузырьковая сортировка (Bubble Sort)**
**Принцип**:  
Сравнивает соседние элементы и меняет их местами, если они в неправильном порядке. За каждый проход наибольший элемент «всплывает» в конец массива.

**Код**:
```java
public static void bubbleSort(int[] arr) {
    int n = arr.length;
    boolean swapped;
    for (int i = 0; i < n - 1; i++) {
        swapped = false;
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                int temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
                swapped = true;
            }
        }
        if (!swapped) break; // Оптимизация: выход при отсутствии перестановок
    }
}
```

---

### 2. **Сортировка выбором (Selection Sort)**
**Принцип**:  
Находит минимальный элемент в неотсортированной части массива и перемещает его в начало. Делит массив на отсортированную (слева) и неотсортированную (справа) части.

**Код**:
```java
public static void selectionSort(int[] arr) {
    int n = arr.length;
    for (int i = 0; i < n - 1; i++) {
        int minIndex = i;
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        int temp = arr[minIndex];
        arr[minIndex] = arr[i];
        arr[i] = temp;
    }
}
```

---

### 3. **Сортировка вставками (Insertion Sort)**
**Принцип**:  
Берёт элемент из неотсортированной части и вставляет его в правильную позицию в отсортированной части массива. Начинается со второго элемента.

**Код**:
```java
public static void insertionSort(int[] arr) {
    int n = arr.length;
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}
```

---

### 4. **Быстрая сортировка (Quick Sort)**
**Принцип**:  
Использует стратегию «разделяй и властвуй». Выбирает опорный элемент, разделяет массив на элементы меньше и больше опорного, рекурсивно сортирует подмассивы.

**Код**:
```java
public static void quickSort(int[] arr, int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high); // Индекс опорного элемента
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}

private static int partition(int[] arr, int low, int high) {
    int pivot = arr[high]; // Опорный элемент (последний)
    int i = low - 1; // Индекс для элементов меньше опорного
    for (int j = low; j < high; j++) {
        if (arr[j] < pivot) {
            i++;
            int temp = arr[i];
            arr[i] = arr[j];
            arr[j] = temp;
        }
    }
    // Перемещаем опорный элемент на место
    int temp = arr[i + 1];
    arr[i + 1] = arr[high];
    arr[high] = temp;
    return i + 1;
}
```

---

### 5. **Сортировка слиянием (Merge Sort)**
**Принцип**:  
Делит массив на две половины, рекурсивно сортирует каждую, затем объединяет их в один отсортированный массив.

**Код**:
```java
public static void mergeSort(int[] arr, int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSort(arr, left, mid);
        mergeSort(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}

private static void merge(int[] arr, int left, int mid, int right) {
    // Создаём временные массивы
    int[] L = Arrays.copyOfRange(arr, left, mid + 1);
    int[] R = Arrays.copyOfRange(arr, mid + 1, right + 1);
    
    int i = 0, j = 0, k = left;
    while (i < L.length && j < R.length) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }
    // Дописываем оставшиеся элементы
    while (i < L.length) {
        arr[k] = L[i];
        i++;
        k++;
    }
    while (j < R.length) {
        arr[k] = R[j];
        j++;
        k++;
    }
}
```

---

### Сравнение алгоритмов
| Алгоритм         | Сложность (в среднем) | Сложность (в худшем) | Память     |
|------------------|-----------------------|----------------------|------------|
| Пузырьковая      | O(n²)                 | O(n²)                | O(1)       |
| Выбором          | O(n²)                 | O(n²)                | O(1)       |
| Вставками        | O(n²)                 | O(n²)                | O(1)       |
| Быстрая          | O(n log n)            | O(n²)                | O(log n)   |
| Слиянием         | O(n log n)            | O(n log n)           | O(n)       |

---

**Пример использования**:
```java
public static void main(String[] args) {
    int[] arr = {5, 3, 8, 4, 2};
    bubbleSort(arr);
    System.out.println(Arrays.toString(arr)); // [2, 3, 4, 5, 8]
}
```

---
---
### 3.	пузырьковая сортировка, сложность, что по памяти
**Пузырьковая сортировка** (Bubble Sort) — это простой алгоритм сортировки, который **работает "на месте"** (in-place), то есть **не требует дополнительной памяти** для хранения промежуточных данных, кроме небольшого количества временных переменных. 

---

### **Сложность по памяти (Space Complexity):**
- **Пространственная сложность:** **O(1)** (константная).  
  Алгоритм использует только **фиксированное количество дополнительной памяти** (например, переменные для временного хранения значений при обмене элементов). Это не зависит от размера входного массива `n`.

---

### **Пример на Java:**
```java
public class BubbleSort {
    public static void bubbleSort(int[] arr) {
        int n = arr.length;
        boolean swapped;
        for (int i = 0; i < n - 1; i++) {
            swapped = false;
            for (int j = 0; j < n - i - 1; j++) {
                if (arr[j] > arr[j + 1]) {
                    // Обмен элементов (требует O(1) дополнительной памяти)
                    int temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                    swapped = true;
                }
            }
            // Если обменов не было, массив уже отсортирован
            if (!swapped) break;
        }
    }

    public static void main(String[] args) {
        int[] arr = {64, 34, 25, 12, 22, 11, 90};
        bubbleSort(arr);
        System.out.println("Отсортированный массив: " + Arrays.toString(arr));
    }
}
```

---

### **Детали:**
1. **In-place алгоритм:**  
   - Все операции выполняются **на исходном массиве** без создания копий.  
   - Для обмена элементов используется **одна временная переменная** (`temp`), что и дает **O(1)** по памяти.

2. **Временная сложность:**  
   - **Лучший случай:** O(n) (если массив уже отсортирован).  
   - **Средний и худший случаи:** O(n²) (из-за вложенных циклов).

---

### **Сравнение с другими алгоритмами:**
| Алгоритм         | Пространственная сложность | Временная сложность (худший случай) |
|-------------------|-----------------------------|--------------------------------------|
| Пузырьковая       | **O(1)**                    | O(n²)                                |
| Быстрая сортировка| O(log n) (стек вызовов)     | O(n²)                                |
| Сортировка слиянием| O(n)                       | O(n log n)                           |
| Сортировка вставками| O(1)                      | O(n²)                                |

---

### **Почему важно знать сложность по памяти?**
- **Эффективность:** Алгоритмы с **O(1)** по памяти подходят для систем с ограниченными ресурсами (например, встроенные устройства).  
- **Оптимизация:** Если данные занимают большой объем, in-place алгоритмы избегают копирования массивов, что экономит память.

**Пузырьковая сортировка** — не самый эффективный алгоритм по времени, но его простота и минимальные требования к памяти делают его полезным для учебных целей или для очень малых массивов.

---
---
### 4.	сортировка выбором, сложность, что по памяти
**Сортировка выбором (Selection Sort)** — это алгоритм сортировки, который последовательно находит минимальный (или максимальный) элемент в неотсортированной части массива и перемещает его в начало.  
Рассмотрим его ключевые характеристики в Java:

---

### **Сложность алгоритма**
- **Временная сложность**:
  - **Лучший случай**: `O(n²)` — даже если массив уже отсортирован, алгоритм выполняет полный перебор.
  - **Средний случай**: `O(n²)` — типичная ситуация для случайных данных.
  - **Худший случай**: `O(n²)` — все элементы расположены в обратном порядке.

- **Пространственная сложность**:  
  **`O(1)`** — алгоритм работает **in-place**, не требуя дополнительной памяти, кроме временных переменных для обмена элементов.

---

### **Как работает в Java**
1. **Поиск минимума**:  
   На каждой итерации находится индекс минимального элемента в неотсортированной части массива.
2. **Обмен элементов**:  
   Минимальный элемент меняется местами с первым элементом неотсортированной части.
3. **Сдвиг границы**:  
   Граница между отсортированной и неотсортированной частью сдвигается на один элемент вправо.

**Пример кода**:
```java
public static void selectionSort(int[] arr) {
    int n = arr.length;
    for (int i = 0; i < n - 1; i++) {
        int minIndex = i;
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j; // Находим индекс минимального элемента
            }
        }
        // Обмен элементов
        int temp = arr[minIndex];
        arr[minIndex] = arr[i];
        arr[i] = temp;
    }
}
```

---

### **Плюсы и минусы**
- **Плюсы**:
  - Простая реализация.
  - Не требует дополнительной памяти (`O(1)` по памяти).
- **Минусы**:
  - Медленный для больших массивов из-за квадратичной сложности `O(n²)`.
  - Не адаптивный: не учитывает частичную упорядоченность массива.

---

### **Сравнение с другими алгоритмами**
| Алгоритм          | Время (среднее) | Память | Подходит для          |
|--------------------|-----------------|--------|-----------------------|
| **Сортировка выбором** | `O(n²)`         | `O(1)` | Маленькие массивы     |
| Быстрая сортировка | `O(n log n)`    | `O(log n)` | Большие массивы      |
| Сортировка вставками | `O(n²)`        | `O(1)` | Частично отсортированные массивы |

---

**Итог**:  
Сортировка выбором — это простой, но неэффективный алгоритм для больших данных. В Java он подходит для задач с ограничением по памяти или при работе с небольшими массивами. Для реальных проектов чаще используют **Quick Sort** или **Merge Sort**.

---
---
### 5.	сортировка вставкой, сложность, что по памяти
**Сортировка вставкой (Insertion Sort)** — это алгоритм сортировки, который последовательно строит отсортированную часть массива, вставляя каждый новый элемент в правильную позицию. Вот ключевые аспекты:

### Как работает:
1. Начинается со второго элемента (индекс `i = 1`).
2. Текущий элемент (`key`) сравнивается с предыдущими элементами отсортированной части.
3. Если предыдущие элементы больше `key`, они сдвигаются вправо.
4. `key` вставляется в освободившуюся позицию.
5. Процесс повторяется для всех элементов массива.

Пример кода на Java:
```java
public static void insertionSort(int[] arr) {
    for (int i = 1; i < arr.length; i++) {
        int key = arr[i];
        int j = i - 1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}
```

### Сложность:
- **Лучший случай**: O(n) (массив уже отсортирован).
- **Средний и худший случаи**: O(n²) (элементы перемещаются в среднем на половину длины отсортированной части).
- **Память**: O(1) (in-place, не требуется дополнительной памяти, кроме временных переменных).

### Особенности в Java:
- **In-place алгоритм**: не создаёт копий массива, сортирует исходные данные.
- **Стабильность**: сохраняет порядок равных элементов.
- **Применение**: эффективен для небольших или частично отсортированных массивов. Используется в стандартных методах (например, `Arrays.sort()` для массивов объектов при небольшом размере).

### Преимущества:
- Прост в реализации.
- Эффективен на небольших данных.
- Адаптивен: скорость увеличивается на частично отсортированных массивах.

**Итог**: Сортировка вставкой — это простой и стабильный алгоритм с квадратичной сложностью в худшем случае, но оптимальный для небольших или почти упорядоченных данных. В Java он работает in-place, не требуя дополнительной памяти.

---
---
### 6.	быстрая сортировка, сложность, что по памяти
**Быстрая сортировка (Quick Sort)** — это алгоритм сортировки, основанный на принципе "разделяй и властвуй". Его эффективность зависит от выбора опорного элемента (pivot) и стратегии разбиения. Давайте разберем его **сложность по памяти** в Java.

---

### **Пространственная сложность (Space Complexity)**
Пространственная сложность быстрой сортировки зависит от реализации:

1. **In-place версия (без дополнительных массивов):**  
   - **Сложность по памяти:** **O(log n)** в среднем случае, **O(n)** в худшем случае.  
     Это связано с глубиной рекурсии и использованием стека вызовов.  
     - **Средний случай:** При сбалансированном разбиении массива (например, выбор медианы) глубина рекурсии будет **O(log n)**.  
     - **Худший случай:** Если массив уже отсортирован, а опорный элемент выбирается как первый/последний элемент, глубина рекурсии достигает **O(n)** (например, для массива `[1, 2, 3, 4, 5]`).

   ```java
   public class QuickSort {
       public static void quickSort(int[] arr, int low, int high) {
           if (low < high) {
               int pi = partition(arr, low, high); // Индекс опорного элемента
               quickSort(arr, low, pi - 1);  // Рекурсия для левой части
               quickSort(arr, pi + 1, high); // Рекурсия для правой части
           }
       }

       private static int partition(int[] arr, int low, int high) {
           int pivot = arr[high]; // Выбор последнего элемента как pivot
           int i = low - 1;
           for (int j = low; j < high; j++) {
               if (arr[j] < pivot) {
                   i++;
                   // Обмен элементов
                   int temp = arr[i];
                   arr[i] = arr[j];
                   arr[j] = temp;
               }
           }
           // Размещение pivot на правильную позицию
           int temp = arr[i + 1];
           arr[i + 1] = arr[high];
           arr[high] = temp;
           return i + 1;
       }

       public static void main(String[] args) {
           int[] arr = {10, 7, 8, 9, 1, 5};
           quickSort(arr, 0, arr.length - 1);
           System.out.println("Отсортированный массив: " + Arrays.toString(arr));
       }
   }
   ```

2. **Не in-place версия (с созданием дополнительных массивов):**  
   - **Сложность по памяти:** **O(n)** из-за копирования данных в новые массивы.  
     Такие реализации редко используются на практике из-за неоптимального использования памяти.

---

### **Временная сложность (Time Complexity)**
- **Средний случай:** **O(n log n)** — при сбалансированном разбиении.  
- **Худший случай:** **O(n²)** — если массив уже отсортирован, а опорный элемент выбран неудачно.  

---

### **Почему O(log n) по памяти в среднем случае?**
- **Рекурсивный стек:**  
  Каждый рекурсивный вызов добавляет в стек кадр с параметрами `low` и `high`.  
  - При сбалансированном разбиении глубина стека пропорциональна **log n** (так как массив делится примерно пополам на каждом шаге).  
  - В худшем случае (например, для отсортированного массива) глубина стека достигает **n** (размер массива).

---

### **Оптимизация памяти**
Чтобы избежать худшего случая **O(n)** по памяти:
1. **Выбор хорошего pivot:**  
   - Случайный выбор (`Randomized Quick Sort`).  
   - Выбор медианы из трех элементов (первый, средний, последний).  
2. **Итеративная реализация:**  
   Замена рекурсии на цикл с использованием стека вручную.  
   ```java
   // Пример итеративной быстрой сортировки
   public static void iterativeQuickSort(int[] arr, int low, int high) {
       Stack<Integer> stack = new Stack<>();
       stack.push(low);
       stack.push(high);

       while (!stack.isEmpty()) {
           high = stack.pop();
           low = stack.pop();
           int pi = partition(arr, low, high);
           if (pi - 1 > low) {
               stack.push(low);
               stack.push(pi - 1);
           }
           if (pi + 1 < high) {
               stack.push(pi + 1);
               stack.push(high);
           }
       }
   }
   ```

---

### **Сравнение с другими алгоритмами**
| Алгоритм          | Пространственная сложность (средний случай) | Временная сложность (средний случай) |
|--------------------|---------------------------------------------|---------------------------------------|
| Быстрая сортировка | **O(log n)**                                | O(n log n)                            |
| Сортировка слиянием| O(n)                                        | O(n log n)                            |
| Сортировка кучей   | O(1)                                        | O(n log n)                            |

---

### **Практические советы для Java**
- В стандартной библиотеке Java метод `Arrays.sort()` для примитивов использует **модифицированную быструю сортировку** (Dual-Pivot QuickSort).  
- Для объектов (например, `Integer[]`) применяется сортировка слиянием (TimSort), так как она устойчивая (stable).  
- Если нужно избежать худшего случая **O(n²)** по времени, используйте `Collections.sort()` или `Arrays.sort()` для объектов.  

---

**Итог:**  
Быстрая сортировка — это компромисс между временем и памятью. При грамотной реализации (in-place + выбор хорошего pivot) она требует **O(log n)** дополнительной памяти в среднем случае и остается одним из самых быстрых алгоритмов на практике.

---
---
### 7.	сортировка слиянием, сложность, что по памяти
---

### **Сортировка слиянием (Merge Sort) в Java: сложность и использование памяти**

#### **Принцип работы**  
Алгоритм делит массив на две половины, рекурсивно сортирует каждую половину, а затем объединяет (сливает) их в один отсортированный массив.  
**Ключевой шаг** — операция слияния (`merge`), где два отсортированных подмассива объединяются в один.

---

### **Временная сложность**  
- **Средний и худший случай**: **O(n log n)**.  
  - Массив делится на две части (O(log n) уровней деления).  
  - На каждом уровне выполняется слияние за O(n) операций.  
  - Итог: **O(n) × O(log n) = O(n log n)**.  

---

### **Использование памяти**  
- **Требуется дополнительная память**: **O(n)**.  
  - При слиянии создаются временные подмассивы для левой и правой частей.  
  - В Java каждый вызов `merge` использует `Arrays.copyOfRange`, что выделяет память под копии элементов.  
  - **Пример**:  
    ```java
    int[] L = Arrays.copyOfRange(arr, left, mid + 1);  // O(n/2) памяти
    int[] R = Arrays.copyOfRange(arr, mid + 1, right + 1);  // O(n/2) памяти
    ```  
  - **Итог**: На каждом уровне рекурсии суммарно используется O(n) памяти, но память освобождается после завершения слияния. Общее потребление — **O(n)**.

---

### **Оптимизации памяти**  
1. **In-place Merge Sort**  
   - Теоретически возможна реализация без выделения дополнительной памяти, но на практике сложна и менее эффективна.  
   - В Java стандартные реализации (например, `Arrays.sort()` для объектов) используют гибридные подходы, но не чистый Merge Sort.  

2. **Один временный массив**  
   - Можно создать один временный массив размером O(n) и переиспользовать его для всех операций слияния, уменьшая накладные расходы.

---

### **Сравнение с другими алгоритмами**  
| Алгоритм       | Память     | Стабильность | Сложность (худший случай) |  
|----------------|------------|--------------|---------------------------|  
| **Merge Sort** | O(n)       | Да           | O(n log n)                |  
| Quick Sort     | O(log n)   | Нет          | O(n²)                     |  
| Heap Sort      | O(1)       | Нет          | O(n log n)                |  

---

### **Пример кода (с выделением O(n) памяти)**  
```java
public static void mergeSort(int[] arr) {
    if (arr.length <= 1) return;
    int[] temp = new int[arr.length];  // Единый временный массив для оптимизации
    mergeSort(arr, 0, arr.length - 1, temp);
}

private static void mergeSort(int[] arr, int left, int right, int[] temp) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSort(arr, left, mid, temp);
        mergeSort(arr, mid + 1, right, temp);
        merge(arr, left, mid, right, temp);  // Переиспользование temp
    }
}

private static void merge(int[] arr, int left, int mid, int right, int[] temp) {
    System.arraycopy(arr, left, temp, left, right - left + 1);  // Копирование в temp
    int i = left, j = mid + 1, k = left;
    while (i <= mid && j <= right) {
        arr[k++] = (temp[i] <= temp[j]) ? temp[i++] : temp[j++];
    }
    while (i <= mid) arr[k++] = temp[i++];
}
```

---

### **Итог**  
- **Сортировка слиянием гарантирует O(n log n)** времени в любом случае, но требует **O(n)** дополнительной памяти.  
- В Java это делает её предпочтительной для сортировки связанных структур (например, `LinkedList`), где доступ к элементам затратен, а копирование данных менее критично.

---
---
### 8.	жадный алгоритм
**Жадные алгоритмы (Greedy Algorithms)** — это подход, при котором на каждом шаге принимается **локально оптимальное решение** в надежде, что совокупность таких решений приведет к **глобально оптимальному решению**. Они не всегда дают идеальный результат, но для некоторых задач работают эффективно и быстро. Ниже разберем принципы, примеры реализации на Java и особенности таких алгоритмов.

---

### **Когда применяются жадные алгоритмы?**
1. **Оптимальная подструктура:** Задача может быть разбита на подзадачи, где выбор на текущем шаге влияет на последующие.  
2. **Свойство жадного выбора:** Локально оптимальное решение ведет к глобально оптимальному.  

---

### **Примеры жадных алгоритмов на Java**

#### **1. Задача о размене монет**  
**Цель:** Найти минимальное количество монет для суммы, используя заданные номиналы.  
**Жадный выбор:** Всегда брать наибольшую доступную монету, не превышающую оставшуюся сумму.  

```java
import java.util.Arrays;
import java.util.Collections;

public class CoinChange {
    public static void main(String[] args) {
        Integer[] coins = {1, 5, 10, 25}; // Номиналы монет
        int amount = 63;
        System.out.println("Минимальное количество монет: " + greedyCoinChange(coins, amount));
    }

    public static int greedyCoinChange(Integer[] coins, int amount) {
        // Сортируем номиналы в убывающем порядке
        Arrays.sort(coins, Collections.reverseOrder());
        int count = 0;

        for (int coin : coins) {
            while (amount >= coin) {
                amount -= coin;
                count++;
            }
            if (amount == 0) break;
        }

        return count;
    }
}
```

**Вывод:**  
```
Минимальное количество монет: 6 (25 + 25 + 10 + 1 + 1 + 1)
```

**Ограничение:**  
Алгоритм работает, только если номиналы монет образуют **каноническую систему** (например, 1, 5, 10, 25). Для произвольных номиналов (например, [1, 3, 4]) жадный подход может дать неоптимальный результат.

---

#### **2. Задача о выборе интервалов**  
**Цель:** Выбрать максимальное количество непересекающихся интервалов.  
**Жадный выбор:** Выбирать интервал с самым ранним окончанием, чтобы освободить место для других.  

```java
import java.util.Arrays;
import java.util.Comparator;

public class IntervalScheduling {
    public static void main(String[] args) {
        int[][] intervals = {{1, 3}, {2, 5}, {4, 6}, {7, 9}, {8, 10}};
        System.out.println("Максимальное количество интервалов: " + selectIntervals(intervals));
    }

    public static int selectIntervals(int[][] intervals) {
        // Сортируем интервалы по времени окончания
        Arrays.sort(intervals, Comparator.comparingInt(a -> a[1]));
        int count = 1;
        int lastEnd = intervals[0][1];

        for (int i = 1; i < intervals.length; i++) {
            if (intervals[i][0] >= lastEnd) {
                count++;
                lastEnd = intervals[i][1];
            }
        }

        return count;
    }
}
```

**Вывод:**  
```
Максимальное количество интервалов: 3 ( [1,3], [4,6], [7,9] )
```

---

### **Плюсы и минусы жадных алгоритмов**
| **Преимущества**                     | **Недостатки**                          |
|--------------------------------------|------------------------------------------|
| Простота реализации.                 | Не всегда дают оптимальное решение.     |
| Высокая скорость (часто O(n log n)). | Требуют доказательства корректности.    |
| Эффективны для специфичных задач.    | Не подходят для задач с зависимостями.  |

---

### **Когда использовать жадные алгоритмы?**
1. **Задача о расписании** (максимизация количества задач).  
2. **Кодирование Хаффмана** (оптимальное префиксное кодирование).  
3. **Алгоритм Дейкстры** (кратчайший путь в графе без отрицательных весов).  

---

### **Почему жадный алгоритм может не сработать?**
Рассмотрим пример **задачи о рюкзаке** (не путать с задачей о рюкзаке с дробными вещами, где жадный подход работает):  
- **Цель:** Выбрать предметы с максимальной суммарной стоимостью, не превышающие вес рюкзака.  
- **Жадный выбор:** Брать предметы с максимальной стоимостью или удельной стоимостью (стоимость/вес).  
- **Проблема:** Локально оптимальный выбор может исключить комбинацию предметов с большей общей стоимостью.  

---

### **Итог**
Жадные алгоритмы — это мощный инструмент для задач, где **локально оптимальные решения ведут к глобальному оптимуму**. Они просты в реализации и работают за линейное или логарифмическое время, но требуют строгого доказательства корректности. В Java их можно применять для решения задач оптимизации, таких как размен монет, выбор интервалов или построение минимальных остовных деревьев (алгоритм Краскала).

---
---
### 9.	бинарный поиск
---

### **Бинарный поиск на Java**

Бинарный поиск — алгоритм для нахождения элемента в **отсортированном массиве** за время **O(log n)**.  
**Принцип работы**:  
1. Сравниваем искомый элемент с элементом в середине массива.  
2. Если элемент найден, возвращаем его индекс.  
3. Если элемент меньше среднего, ищем в левой половине массива.  
4. Если элемент больше среднего, ищем в правой половине.  
5. Повторяем, пока не найдем элемент или не закончится массив.

---

### **Реализация (итеративный подход)**
```java
public static int binarySearch(int[] arr, int target) {
    int left = 0;
    int right = arr.length - 1;

    while (left <= right) {
        int mid = left + (right - left) / 2; // Защита от переполнения

        if (arr[mid] == target) {
            return mid; // Элемент найден
        } else if (arr[mid] < target) {
            left = mid + 1; // Ищем в правой половине
        } else {
            right = mid - 1; // Ищем в левой половине
        }
    }
    return -1; // Элемент не найден
}
```

---

### **Реализация (рекурсивный подход)**
```java
public static int binarySearchRecursive(int[] arr, int target, int left, int right) {
    if (left > right) {
        return -1; // Базовый случай: элемент не найден
    }

    int mid = left + (right - left) / 2;

    if (arr[mid] == target) {
        return mid;
    } else if (arr[mid] < target) {
        return binarySearchRecursive(arr, target, mid + 1, right); // Ищем справа
    } else {
        return binarySearchRecursive(arr, target, left, mid - 1); // Ищем слева
    }
}
```

---

### **Пример использования**
```java
public static void main(String[] args) {
    int[] sortedArray = {2, 5, 8, 12, 16, 23, 38, 45};
    int target = 23;

    // Итеративный поиск
    int index = binarySearch(sortedArray, target);
    System.out.println("Итеративный подход: Индекс " + index); // 5

    // Рекурсивный поиск
    int indexRecursive = binarySearchRecursive(sortedArray, target, 0, sortedArray.length - 1);
    System.out.println("Рекурсивный подход: Индекс " + indexRecursive); // 5
}
```

---

### **Особенности бинарного поиска**
1. **Массив должен быть отсортирован**.  
   Если массив не отсортирован, результат непредсказуем.  
   Например, для `{5, 2, 8, 1}` поиск `8` может вернуть неверный индекс.

2. **Сложность**:  
   - Время: **O(log n)** — каждый шаг уменьшает зону поиска вдвое.  
   - Память: **O(1)** для итеративного подхода, **O(log n)** для рекурсивного (из-за стека вызовов).

---

### **Встроенный метод в Java**
В Java есть стандартная реализация бинарного поиска в классе `Arrays`:  
```java
import java.util.Arrays;

int index = Arrays.binarySearch(sortedArray, target); 
// Возвращает индекс или отрицательное число, если элемент не найден.
```

---

### **Когда использовать?**
- Для поиска в **статических данных** (массив не меняется часто).  
- Если массив отсортирован, бинарный поиск эффективнее линейного (O(n)).  
- Примеры: поиск в словарях, базах данных, игровых рейтингах.

---

### **Ошибки при реализации**
1. **Неправильные границы**:  
   - `left` должно быть `0`, `right` — `arr.length - 1` (индексы начинаются с 0).  
   - Условие `left <= right` обязательно, иначе можно пропустить элемент.

2. **Переполнение при вычислении mid**:  
   - Неправильно: `mid = (left + right) / 2`.  
   - Правильно: `mid = left + (right - left) / 2`.

---

**Итог**: Бинарный поиск — мощный алгоритм для работы с отсортированными данными. Всегда проверяйте, что массив отсортирован, перед его использованием!

---
---
### 10.	Алгоритмы поиска пути: обход в глубину, обход в ширину
**Алгоритмы поиска пути: DFS (Depth-First Search) и BFS (Breadth-First Search)**  
Эти алгоритмы используются для обхода графов и поиска пути между вершинами. Разница в стратегии:  
- **DFS** (обход в глубину) исследует путь до конца, прежде чем вернуться (использует **стек** или **рекурсию**).  
- **BFS** (обход в ширину) исследует все соседние вершины уровня за уровнем (использует **очередь**).  

---

### **Пример графа для теста**
```java
import java.util.*;

public class GraphTraversal {
    static class Graph {
        private int V; // Количество вершин
        private LinkedList<Integer>[] adj; // Список смежности

        Graph(int v) {
            V = v;
            adj = new LinkedList[v];
            for (int i = 0; i < v; ++i) adj[i] = new LinkedList<>();
        }

        // Добавление ребра
        void addEdge(int v, int w) {
            adj[v].add(w);
        }
    }
}
```

---

### **1. Реализация DFS (итеративно и рекурсивно)**  
**Итеративный DFS:**
```java
void DFSIterative(int start) {
    boolean[] visited = new boolean[V];
    Stack<Integer> stack = new Stack<>();
    stack.push(start);

    while (!stack.isEmpty()) {
        int current = stack.pop();
        if (!visited[current]) {
            System.out.print(current + " ");
            visited[current] = true;
            // Добавляем соседей в обратном порядке для правильного обхода
            Collections.reverse(adj[current]);
            for (int neighbor : adj[current]) {
                if (!visited[neighbor]) stack.push(neighbor);
            }
        }
    }
}
```

**Рекурсивный DFS:**
```java
void DFSRecursive(int v, boolean[] visited) {
    visited[v] = true;
    System.out.print(v + " ");
    for (int neighbor : adj[v]) {
        if (!visited[neighbor]) DFSRecursive(neighbor, visited);
    }
}

void DFS(int start) {
    boolean[] visited = new boolean[V];
    DFSRecursive(start, visited);
}
```

---

### **2. Реализация BFS**
```java
void BFS(int start) {
    boolean[] visited = new boolean[V];
    Queue<Integer> queue = new LinkedList<>();
    queue.add(start);
    visited[start] = true;

    while (!queue.isEmpty()) {
        int current = queue.poll();
        System.out.print(current + " ");
        for (int neighbor : adj[current]) {
            if (!visited[neighbor]) {
                visited[neighbor] = true;
                queue.add(neighbor);
            }
        }
    }
}
```

---

### **Пример использования**
```java
public static void main(String[] args) {
    Graph g = new Graph(5);
    g.addEdge(0, 1);
    g.addEdge(0, 2);
    g.addEdge(1, 3);
    g.addEdge(2, 4);
    g.addEdge(3, 4);

    System.out.println("DFS (итеративно):");
    g.DFSIterative(0); // 0 2 4 1 3 

    System.out.println("\nDFS (рекурсивно):");
    g.DFS(0); // 0 1 3 4 2 

    System.out.println("\nBFS:");
    g.BFS(0); // 0 1 2 3 4 
}
```

---

### **Разница между DFS и BFS**
| **Параметр**      | **DFS**                          | **BFS**                          |
|--------------------|----------------------------------|----------------------------------|
| **Структура данных** | Стек (LIFO)                     | Очередь (FIFO)                  |
| **Порядок обхода**  | Уходит "вглубь"                 | Идет "вширь" уровень за уровнем |
| **Применение**      | Поиск в лабиринтах, топ. сортировка | Кратчайший путь в невзвешенном графе |

---

### **Сложность алгоритмов**
- **Временная сложность:** O(V + E) для обоих алгоритмов, где V — вершины, E — рёбра.  
- **Пространственная сложность:**  
  - DFS: O(V) (глубина стека/рекурсии).  
  - BFS: O(V) (размер очереди).  

---

### **Когда использовать?**
- **DFS:**  
  - Поиск любого пути между вершинами.  
  - Проверка связности графа.  
  - Топологическая сортировка.  
- **BFS:**  
  - Поиск кратчайшего пути в невзвешенном графе.  
  - Обход уровней (например, поиск ближайшего соседа).  

**Оба алгоритма** — фундаментальные инструменты для работы с графами. Выбор зависит от задачи и структуры данных.

---
---
### 11.	какие структуры данных в знаете
---

### **Основные структуры данных в Java**

В Java структуры данных реализованы через **Java Collections Framework (JCF)** и другие библиотеки.  
Вот основные категории и их реализации:

---

### **1. Линейные структуры**
#### **Списки (Интерфейс `List`)**  
- **`ArrayList`**  
  - Динамический массив.  
  - Быстрый доступ по индексу (`O(1)`), медленные вставка/удаление в середине (`O(n)`).  
- **`LinkedList`**  
  - Двусвязный список.  
  - Быстрые вставка/удаление (`O(1)`), медленный доступ по индексу (`O(n)`).  
- **`Vector`** (устаревший)  
  - Потокобезопасный аналог `ArrayList`, но медленнее.  
- **`Stack`** (не рекомендуется)  
  - Стек (LIFO). Лучше использовать `Deque`.

#### **Очереди (Интерфейсы `Queue`, `Deque`)**  
- **`ArrayDeque`**  
  - Двусторонняя очередь на основе массива.  
- **`PriorityQueue`**  
  - Очередь с приоритетом (элементы упорядочены).  
- **`LinkedList`**  
  - Может использоваться как очередь, но неэффективна для больших данных.

---

### **2. Ассоциативные структуры**
#### **Множества (Интерфейс `Set`)**  
- **`HashSet`**  
  - Хранит уникальные элементы без порядка. Основан на `HashMap`.  
  - Вставка/поиск: `O(1)`.  
- **`LinkedHashSet`**  
  - Сохраняет порядок добавления элементов.  
- **`TreeSet`**  
  - Элементы сортируются (на основе красно-черного дерева).  
  - Вставка/поиск: `O(log n)`.

#### **Словари (Интерфейс `Map`)**  
- **`HashMap`**  
  - Пары ключ-значение. Быстрый доступ (`O(1)`).  
  - Коллизии разрешаются через цепочки (Java 7) или деревья (Java 8+).  
- **`LinkedHashMap`**  
  - Сохраняет порядок добавления ключей.  
- **`TreeMap`**  
  - Ключи сортируются (красно-черное дерево).  
  - Вставка/поиск: `O(log n)`.  
- **`Hashtable`** (устаревший)  
  - Потокобезопасный аналог `HashMap`, но медленнее.  

---

### **3. Потокобезопасные структуры (из `java.util.concurrent`)**  
- **`ConcurrentHashMap`**  
  - Потокобезопасный `HashMap` с сегментированным доступом.  
- **`CopyOnWriteArrayList`**  
  - Потокобезопасный `ArrayList`. При изменении создается копия.  
- **`BlockingQueue`**  
  - Очереди для многопоточности (например, `ArrayBlockingQueue`, `LinkedBlockingQueue`).  

---

### **4. Специализированные структуры**
- **`EnumSet` / `EnumMap`**  
  - Оптимизированы для работы с перечислениями (`enum`).  
- **`WeakHashMap`**  
  - Ключи могут быть удалены сборщиком мусора, если на них нет ссылок.  
- **`IdentityHashMap`**  
  - Сравнение ключей через `==`, а не `equals()`.  

---

### **5. Графы и деревья**  
В стандартной библиотеке нет готовых реализаций. Обычно создаются самостоятельно:  
- **Деревья**:  
  ```java
  class TreeNode {
      int value;
      List<TreeNode> children;
  }
  ```
- **Графы**:  
  Реализуются через списки смежности или матрицы смежности.

---

### **6. Сторонние библиотеки**  
- **Guava (Google)**  
  - `Multimap`, `Multiset`, `BiMap` и другие расширенные коллекции.  
- **Apache Commons Collections**  
  - `BidiMap`, `CircularFifoQueue`, `Trie`.  

---

### **Как выбрать структуру данных?**  
- **Быстрый доступ по индексу** → `ArrayList`.  
- **Частые вставки/удаления** → `LinkedList`.  
- **Уникальные элементы** → `HashSet` / `TreeSet`.  
- **Ключ-значение** → `HashMap` / `TreeMap`.  
- **Потокобезопасность** → `ConcurrentHashMap`, `CopyOnWriteArrayList`.  

---

**Пример использования `HashMap`:**  
```java
Map<String, Integer> map = new HashMap<>();
map.put("apple", 10);
map.put("banana", 5);
System.out.println(map.get("apple")); // 10
```

**Пример `TreeSet`:**  
```java
Set<Integer> sortedSet = new TreeSet<>();
sortedSet.add(5);
sortedSet.add(2);
sortedSet.add(8);
System.out.println(sortedSet); // [2, 5, 8]
```

---

**Итог:**  
Java предоставляет богатый набор структур данных для разных задач. Выбор зависит от требований к скорости, памяти и потокобезопасности.

---
---
### 12.	массивы достоинства недостатки
### Массивы в Java: достоинства и недостатки

#### **Достоинства**
1. **Высокая производительность**  
   Массивы обеспечивают быстрый доступ к элементам по индексу за время \(O(1)\), так как данные хранятся в непрерывном блоке памяти.  
   Пример:
   ```java
   int[] arr = new int[5];
   arr[2] = 10; // Быстрый доступ
   ```

2. **Поддержка примитивных типов**  
   Массивы могут хранить примитивы (`int`, `char` и т.д.), что экономит память по сравнению с коллекциями, где примитивы оборачиваются в объекты (например, `Integer`).  
   Пример:
   ```java
   int[] numbers = {1, 2, 3}; // Экономия памяти
   ```

3. **Простота использования**  
   Минимальный синтаксис для создания и работы с данными.  
   Пример:
   ```java
   String[] names = {"Alice", "Bob"};
   ```

4. **Безопасность типов**  
   Массивы проверяют типы элементов на этапе выполнения.  
   Пример:
   ```java
   Object[] objArr = new String[3];
   objArr[0] = 5; // Вызовет ArrayStoreException
   ```

---

#### **Недостатки**
1. **Фиксированный размер**  
   Размер массива задаётся при создании и не может быть изменён. Для расширения нужно создавать новый массив и копировать данные.  
   Пример:
   ```java
   int[] arr = {1, 2, 3};
   int[] newArr = Arrays.copyOf(arr, 5); // Копирование
   ```

2. **Отсутствие методов для работы с данными**  
   Нет встроенных методов для добавления, удаления или поиска элементов (в отличие от `ArrayList` или `LinkedList`).  
   Пример:
   ```java
   // Удаление элемента требует ручного копирования
   int[] arr = {1, 2, 3};
   int[] reducedArr = new int[2];
   System.arraycopy(arr, 0, reducedArr, 0, 2);
   ```

3. **Ошибки при работе с индексами**  
   Выход за границы массива вызывает исключение `ArrayIndexOutOfBoundsException`.  
   Пример:
   ```java
   int[] arr = new int[3];
   arr[5] = 10; // Ошибка: ArrayIndexOutOfBoundsException
   ```

4. **Несовместимость с коллекциями**  
   Массивы не реализуют интерфейсы `Collection` или `Iterable`, что усложняет их интеграцию с методами, рассчитанными на коллекции.

---

#### **Сравнение с коллекциями**
| **Критерий**         | **Массивы**                          | **Коллекции (например, ArrayList)**         |
|-----------------------|--------------------------------------|---------------------------------------------|
| Размер                | Фиксированный                       | Динамический                                |
| Примитивные типы      | Поддерживают                        | Требуют обёрток (Integer, Character)        |
| Производительность    | Выше (минимум накладных расходов)   | Ниже (из-за методов и обёрток)              |
| Удобство методов      | Нет методов для добавления/удаления | Богатый API (add(), remove(), contains())   |
| Безопасность типов    | Проверка на этапе выполнения        | Дженерики с проверкой на этапе компиляции   |

---

#### **Когда использовать массивы?**
- Когда размер данных известен заранее и не меняется.
- Для работы с примитивными типами (оптимизация памяти).
- В высокопроизводительных задачах (например, математические вычисления).

#### **Когда выбрать коллекции?**
- При работе с динамическими данными.
- Для использования методов работы с данными (сортировка, фильтрация).
- Если нужна интеграция с библиотеками, ожидающими коллекции.

Пример замены массива на `ArrayList`:
```java
List<Integer> list = new ArrayList<>();
list.add(10); // Динамическое расширение
list.remove(0); // Удобное удаление
```

**Вывод:** Массивы в Java эффективны для статических данных, но уступают коллекциям в гибкости. Выбор зависит от конкретной задачи.

---
---
### 13.	связанные списки, достоинства недостатки временная сложность добавления/поиск/удаления элемента
**Связанные списки** — это структура данных, состоящая из узлов, каждый из которых содержит данные и ссылки на соседние элементы. В Java реализованы через `LinkedList` (двусвязный список), где каждый узел хранит ссылки на предыдущий и следующий элементы.

### **Достоинства:**
1. **Динамический размер**: Память выделяется по мере добавления элементов.
2. **Быстрые вставка и удаление** в начале/конце списка:  
   - Добавление/удаление в начало (`addFirst()`, `removeFirst()`) и конец (`addLast()`, `removeLast()`) выполняется за **O(1)**.  
   - Вставка/удаление в середину **после поиска позиции** — **O(1)** (но поиск позиции занимает O(n)).
3. **Эффективность при частых изменениях**: Не требуется перераспределять память или сдвигать элементы, как в массиве.

### **Недостатки:**
1. **Медленный доступ по индексу**: Для доступа к элементу требуется перебор от начала/конца списка, что занимает **O(n)**.
2. **Большой расход памяти**: Каждый узел хранит две ссылки (в двусвязном списке), что увеличивает накладные расходы по сравнению с массивами (например, `ArrayList`).
3. **Неэффективный поиск**: Поиск элемента по значению выполняется за **O(n)**.

---

### **Временная сложность операций в Java `LinkedList`:**
| **Операция**                     | **Сложность** | **Пояснение**                                                                 |
|-----------------------------------|---------------|-------------------------------------------------------------------------------|
| Добавление в начало (`addFirst()`) | O(1)          | Изменение ссылки на голову списка.                                           |
| Добавление в конец (`addLast()`)   | O(1)          | Есть ссылка на хвост списка.                                                 |
| Вставка в произвольную позицию    | O(n)          | Поиск позиции занимает O(n), вставка — O(1).                                 |
| Удаление с начала (`removeFirst()`) | O(1)          | Изменение ссылки на голову.                                                  |
| Удаление с конца (`removeLast()`)  | O(1)          | Есть ссылка на хвост.                                                        |
| Удаление по индексу/значению      | O(n)          | Поиск элемента занимает O(n), само удаление — O(1).                          |
| Поиск по индексу (`get(index)`)    | O(n)          | Требуется перебор элементов.                                                 |
| Поиск по значению (`contains()`)   | O(n)          | Проверка каждого элемента.                                                   |

---

### **Сравнение с ArrayList**
- **ArrayList** лучше подходит для:  
  - Частого доступа по индексу (O(1)).  
  - Частого добавления в конец (амортизированное O(1)).  
- **LinkedList** выгоден при:  
  - Частых вставках/удалениях в начале/середине списка (если есть итератор).  
  - Реализации очереди или стека (операции `addFirst()`, `removeLast()` и т.д.).

---

**Итог:**  
Выбор между `LinkedList` и `ArrayList` зависит от задач. Если нужны частые изменения в середине списка или работа с очередями — `LinkedList` предпочтителен. Для быстрого доступа по индексу и работы с данными в конце списка лучше подходит `ArrayList`.

---
---
### 14.	стэк, достоинства недостатки временная сложность добавления/поиск/удаления элемента
### Временная сложность операций и характеристики структур данных в Java

#### 1. **ArrayList**
- **Основа:** Динамический массив.
- **Достоинства:**
  - Быстрый доступ по индексу: `O(1)`.
  - Эффективное использование памяти (меньше накладных расходов, чем у LinkedList).
- **Недостатки:**
  - Вставка/удаление в середину: `O(n)` (сдвиг элементов).
  - Увеличение размера массива требует копирования данных: `O(n)`.
- **Сложность операций:**
  - Добавление:
    - В конец (в среднем): `O(1)`.
    - В середину/начало: `O(n)`.
  - Поиск (по индексу): `O(1)`.
  - Поиск (по значению, `contains()`): `O(n)`.
  - Удаление: `O(n)` (сдвиг элементов).

#### 2. **LinkedList**
- **Основа:** Двусвязный список.
- **Достоинства:**
  - Быстрая вставка/удаление в начало/конец: `O(1)`.
  - Вставка/удаление в середину (если известна позиция): `O(1)`.
- **Недостатки:**
  - Медленный доступ по индексу: `O(n)`.
  - Больше накладных расходов на хранение ссылок.
- **Сложность операций:**
  - Добавление:
    - В начало/конец: `O(1)`.
    - В середину (без учета поиска позиции): `O(1)` (но поиск позиции: `O(n)`).
  - Поиск (по индексу или значению): `O(n)`.
  - Удаление (если позиция известна): `O(1)`.

#### 3. **HashSet**
- **Основа:** Хэш-таблица.
- **Достоинства:**
  - Средняя сложность добавления/поиска/удаления: `O(1)`.
- **Недостатки:**
  - В худшем случае (коллизии): `O(n)`.
  - Нет порядка элементов.
- **Сложность операций:**
  - Добавление: `O(1)` (в среднем), `O(n)` (в худшем случае).
  - Поиск (`contains()`): `O(1)` (в среднем), `O(n)` (в худшем случае).
  - Удаление: `O(1)` (в среднем), `O(n)` (в худшем случае).

#### 4. **TreeSet**
- **Основа:** Красно-черное дерево.
- **Достоинства:**
  - Элементы отсортированы.
  - Гарантированная сложность: `O(log n)` для всех операций.
- **Недостатки:**
  - Медленнее, чем HashSet (из-за `O(log n)`).
- **Сложность операций:**
  - Добавление: `O(log n)`.
  - Поиск: `O(log n)`.
  - Удаление: `O(log n)`.

#### 5. **HashMap**
- **Основа:** Хэш-таблица.
- **Достоинства/Недостатки:** Аналогично HashSet.
- **Сложность операций:**
  - Добавление/поиск/удаление: `O(1)` (в среднем), `O(n)` (в худшем случае).

#### 6. **TreeMap**
- **Основа:** Красно-черное дерево.
- **Достоинства/Недостатки:** Аналогично TreeSet.
- **Сложность операций:**
  - Добавление/поиск/удаление: `O(log n)`.

#### 7. **ArrayDeque**
- **Основа:** Массив с возможностью циклического использования.
- **Достоинства:**
  - Быстрая вставка/удаление с обоих концов: `O(1)`.
- **Недостатки:**
  - Доступ к элементам в середине: `O(n)`.
- **Сложность операций:**
  - Добавление/удаление в начало/конец: `O(1)`.
  - Поиск: `O(n)`.

#### 8. **PriorityQueue**
- **Основа:** Двоичная куча.
- **Достоинства:**
  - Быстрое извлечение минимального/максимального элемента: `O(1)`.
- **Недостатки:**
  - Вставка: `O(log n)`.
- **Сложность операций:**
  - Добавление: `O(log n)`.
  - Удаление (извлечение элемента): `O(log n)`.
  - Поиск: `O(n)`.

### Итоговая таблица

| Структура       | Добавление         | Поиск             | Удаление          | Особенности                          |
|-----------------|--------------------|-------------------|-------------------|--------------------------------------|
| **ArrayList**   | O(1) (конец) / O(n)| O(1) (по индексу) | O(n)              | Быстрый доступ по индексу.           |
| **LinkedList**  | O(1)               | O(n)              | O(1) (если известна позиция)| Быстрые вставки в начало/конец.      |
| **HashSet**     | O(1)*              | O(1)*             | O(1)*             | Нет порядка элементов.               |
| **TreeSet**     | O(log n)           | O(log n)          | O(log n)          | Элементы отсортированы.              |
| **HashMap**     | O(1)*              | O(1)*             | O(1)*             | Ключи не упорядочены.                |
| **TreeMap**     | O(log n)           | O(log n)          | O(log n)          | Ключи отсортированы.                 |
| **ArrayDeque**  | O(1)               | O(n)              | O(1)              | Эффективен для очередей/стэков.      |
| **PriorityQueue**| O(log n)          | O(n)              | O(log n)          | Минимум/максимум извлекается за O(1).|

*В среднем случае. В худшем случае (коллизии) — O(n).

### Рекомендации:
- **ArrayList** — если нужен быстрый доступ по индексу и редко меняется размер.
- **LinkedList** — если часто вставляются/удаляются элементы в начале/конце.
- **HashSet/HashMap** — для быстрого поиска, если порядок элементов не важен.
- **TreeSet/TreeMap** — если требуется сортировка или диапазонные запросы.
- **ArrayDeque** — для реализации стэков или очередей.
- **PriorityQueue** — для работы с элементами по приоритету.


---
---
### 15.	очередь, достоинства недостатки временная сложность добавления/поиск/удаления элемента
### Очередь в Java: основные аведения
Очередь (Queue) — структура данных, работающая по принципу **FIFO** (First-In-First-Out). В Java интерфейс `Queue` реализуется классами `LinkedList`, `ArrayDeque`, `PriorityQueue` и другими. Рассмотрим особенности, достоинства, недостатки и временную сложность операций.

---

### **Достоинства**
1. **Простота и предсказуемость**:
   - Чёткий порядок обработки элементов (первым пришёл — первым обработан).
   - Идеально подходит для задач вроде BFS (поиск в ширину), буферизации данных или планирования задач.

2. **Эффективные базовые операции**:
   - Добавление (`offer()`) и удаление (`poll()`) элементов выполняются за **O(1)** в `LinkedList` и `ArrayDeque`.

3. **Гибкость реализаций**:
   - `ArrayDeque` — эффективная реализация на основе массива (кольцевой буфер).
   - `LinkedList` — позволяет использовать очередь как двустороннюю (Deque).
   - `PriorityQueue` — поддерживает приоритеты элементов (но нарушает FIFO).

4. **Потокобезопасные варианты**:
   - Например, `ConcurrentLinkedQueue` и блокирующие очереди (`ArrayBlockingQueue`) для многопоточности.

---

### **Недостатки**
1. **Ограниченный доступ**:
   - Нет прямого доступа к элементам по индексу (только к голове и хвосту).
   - Поиск элемента по значению требует перебора (**O(n)**).

2. **Затраты на расширение**:
   - В `ArrayDeque` при переполнении массива происходит копирование данных (**O(n)**), но амортизированная сложность добавления остаётся **O(1)**.

3. **Неэффективность для произвольных операций**:
   - Вставка/удаление в середине невозможно без использования дополнительных структур данных.

4. **Приоритетная очередь**:
   - `PriorityQueue` нарушает FIFO, а операции вставки/удаления работают за **O(log n)** из-за структуры кучи.

---

### **Временная сложность операций**
Рассмотрим для двух популярных реализаций: **LinkedList** и **ArrayDeque**.

| **Операция**               | `LinkedList`       | `ArrayDeque`       | `PriorityQueue`    |
|----------------------------|--------------------|--------------------|--------------------|
| **Добавление (`offer()`)** | O(1)               | O(1) (амортизир.) | O(log n)           |
| **Удаление (`poll()`)**    | O(1)               | O(1)               | O(log n)           |
| **Поиск элемента**         | O(n)               | O(n)               | O(n)               |
| **Доступ к голове (`peek()`)** | O(1)          | O(1)               | O(1)               |

---

### **Когда использовать очередь?**
- **Рекомендуется**:
  - Обработка задач в порядке поступления.
  - Реализация BFS, кэширования, буферизации.
  - Многопоточные задачи (с использованием `BlockingQueue`).

- **Не рекомендуется**:
  - Частый поиск элементов по значению (используйте `HashSet` или `HashMap`).
  - Работа с элементами в середине коллекции (выберите `ArrayList` или `LinkedList` как `List`).

---

### **Итог**
Очередь в Java — удобный инструмент для работы с данными в порядке FIFO. Для большинства операций добавления/удаления она обеспечивает константную временную сложность (**O(1)**), но поиск по значению остаётся неэффективным (**O(n)**). Выбор реализации зависит от задачи:
- `ArrayDeque` — для однопоточных приложений с высокой производительностью.
- `LinkedList` — если нужна двусторонняя очередь (Deque) или частые вставки/удаления в середину (но это уже не FIFO).
- `PriorityQueue` — для обработки элементов по приоритету.

---
---
### 16.	деревья достоинства недостатки временная сложность добавления/поиск/удаления элемента
### Деревья в Java: Достоинства, Недостатки и Временная Сложность

В Java деревья используются для хранения упорядоченных данных. Основные реализации включают **бинарные деревья поиска (BST)**, **сбалансированные деревья** (например, красно-черные в `TreeMap` и `TreeSet`), а также **кучи** (для приоритетных очередей). Рассмотрим их особенности.

---

### 1. Бинарное Дерево Поиска (BST)
**Достоинства**:
- Простая реализация.
- В среднем случае операции добавления, поиска и удаления выполняются за **O(log n)**.
- Поддерживает упорядоченность элементов.

**Недостатки**:
- В худшем случае (вырожденное дерево) сложность операций **O(n)**.
- Не гарантирует сбалансированность.

**Временная сложность**:
| Операция  | Средний случай | Худший случай |
|-----------|----------------|---------------|
| Добавление | O(log n)       | O(n)          |
| Поиск     | O(log n)       | O(n)          |
| Удаление  | O(log n)       | O(n)          |

---

### 2. Сбалансированные Деревья (Красно-Черные, AVL)
Используются в `TreeMap` и `TreeSet`.  
**Достоинства**:
- Гарантированная сбалансированность.
- Все операции выполняются за **O(log n)** даже в худшем случае.
- Поддерживают упорядоченность данных.

**Недостатки**:
- Большие накладные расходы на поддержание баланса (например, повороты узлов).
- Немного медленнее, чем хэш-структуры (например, `HashMap`).

**Временная сложность**:
| Операция  | Сложность      |
|-----------|----------------|
| Добавление | O(log n)       |
| Поиск     | O(log n)       |
| Удаление  | O(log n)       |

---

### 3. Двоичная Куча (Heap)
Используется в `PriorityQueue`.  
**Достоинства**:
- Быстрое извлечение минимума/максимума за **O(1)**.
- Вставка и удаление за **O(log n)**.

**Недостатки**:
- Поиск произвольного элемента выполняется за **O(n)**.
- Не поддерживает упорядоченность всех элементов (только частичную).

**Временная сложность**:
| Операция      | Сложность      |
|---------------|----------------|
| Добавление    | O(log n)       |
| Поиск         | O(n)           |
| Удаление      | O(log n)       |

---

### Сравнение с Другими Структурами
- **HashMap**:
  - Вставка/поиск/удаление за **O(1)** (в среднем случае).
  - Не поддерживает порядок элементов.
- **LinkedList**:
  - Вставка/удаление в середине за **O(n)**.
  - Поиск за **O(n)**.

---

### Когда Использовать Деревья?
- Если требуется **упорядоченность данных** (например, диапазонные запросы).
- Для гарантированной **предсказуемой производительности** (O(log n)).
- Когда нужны операции, основанные на порядке (например, `first()`, `last()`, `ceiling()`).

---

### Итог
- **TreeMap/TreeSet** (красно-черные деревья):  
  Подходят для задач с частыми операциями поиска/вставки/удаления и необходимостью упорядочивания.
- **PriorityQueue** (куча):  
  Оптимальна для приоритетных задач, но не для произвольного поиска.
- **BST**:  
  Используется редко из-за риска вырождения, но служит основой для более сложных структур.

---
---
### 17.	На какие основные группы можно поделить типы данных?
В Java типы данных делятся на две основные группы:

### 1. **Примитивные типы (Primitive Types)**  
Простые, неделимые типы, хранящие значение непосредственно в памяти. Всего 8 видов:  
- **Целочисленные**:  
  - `byte` (8 бит, от -128 до 127)  
  - `short` (16 бит, от -32 768 до 32 767)  
  - `int` (32 бита, от -2³¹ до 2³¹–1)  
  - `long` (64 бита, от -2⁶³ до 2⁶³–1)  

- **С плавающей точкой**:  
  - `float` (32 бита)  
  - `double` (64 бита)  

- **Символьный**:  
  - `char` (16 бит, Unicode-символ, например, `'A'`)  

- **Логический**:  
  - `boolean` (true/false).  

**Особенности**:  
- Хранятся в стеке (stack memory).  
- Не могут быть `null` (всегда имеют значение).  
- Быстрые в работе из-за отсутствия накладных расходов.  

---

### 2. **Ссылочные типы (Reference Types)**  
Хранят ссылку (адрес) на объект в памяти (куче — heap memory). Примеры:  
- **Объекты классов** (например, `String`, `ArrayList`, пользовательские классы).  
- **Массивы** (например, `int[]`, `String[][]`).  
- **Интерфейсы** (переменные интерфейсного типа).  

**Особенности**:  
- Значение по умолчанию — `null`.  
- Требуют создания объекта через `new` (кроме литералов, например, `String s = "Hello";`).  
- Позволяют использовать методы и поля класса.  
- Поддерживают наследование и полиморфизм.  

---

**Дополнительно**:  
- **Автоупаковка/распаковка** (autoboxing/unboxing): автоматическое преобразование между примитивами и их обёртками (например, `int` ↔ `Integer`).  
- **Обёртки** (Wrapper Classes): `Integer`, `Double`, `Boolean` и т.д. — используются, когда нужна объектная форма примитивов.  

Пример:  
```java
int primitiveInt = 42;          // Примитивный тип
Integer referenceInt = 42;      // Ссылочный тип (автоупаковка)
String text = "Java";           // Ссылочный тип (объект String)
int[] numbers = {1, 2, 3};      // Ссылочный тип (массив)
```

---
---
### 18.	Какие примитивные типы вы знаете?
В Java существует 8 примитивных типов данных. Они используются для хранения простых значений и не являются объектами. Вот их список с краткими характеристиками:

### 1. Целочисленные типы
- **`byte`**  
  - Размер: 1 байт (8 бит)  
  - Диапазон: от -128 до 127  
  - Пример: `byte a = 100;`

- **`short`**  
  - Размер: 2 байта (16 бит)  
  - Диапазон: от -32 768 до 32 767  
  - Пример: `short b = 30_000;`

- **`int`**  
  - Размер: 4 байта (32 бита)  
  - Диапазон: от -2³¹ до 2³¹–1  
  - Пример: `int c = 2_000_000_000;`

- **`long`**  
  - Размер: 8 байтов (64 бита)  
  - Диапазон: от -2⁶³ до 2⁶³–1  
  - Пример: `long d = 9_000_000_000_000L;` (требуется суффикс `L`)

### 2. Типы с плавающей точкой
- **`float`**  
  - Размер: 4 байта (32 бита)  
  - Пример: `float e = 3.14f;` (требуется суффикс `f`)

- **`double`**  
  - Размер: 8 байтов (64 бита)  
  - Пример: `double f = 2.71828;` (по умолчанию для дробных чисел)

### 3. Символьный тип
- **`char`**  
  - Размер: 2 байта (16 бит)  
  - Хранит символы Unicode (от `\u0000` до `\uffff`)  
  - Пример: `char g = 'A';` или `char h = '\u0041';` (символ 'A')

### 4. Логический тип
- **`boolean`**  
  - Может принимать `true` или `false`  
  - Размер не определен стандартом (зависит от JVM)  
  - Пример: `boolean flag = true;`

### Особенности:
- Примитивные типы хранятся в стеке (stack memory), что делает их использование быстрым.
- Не имеют методов (в отличие от объектов-обёрток, например, `Integer` для `int`).
- Инициализируются значением по умолчанию (например, `0` для чисел, `false` для `boolean`), если объявлены как поля класса.

---
---
### 19.	Что вы знаете о преобразовании примитивных типов данных, есть ли потеря данных, можно ли преобразовать логический тип?
**Преобразование примитивных типов в Java**  
В Java преобразования примитивных типов делятся на **расширяющие (widening)** и **сужающие (narrowing)**.  
- **Расширяющие преобразования** выполняются автоматически и безопасны (без потери данных), так как целевой тип больше исходного.  
  Пример: `int → long`, `float → double`.  
  ```java
  int a = 100;
  long b = a; // Автоматическое преобразование (без потерь).
  ```

- **Сужающие преобразования** требуют явного приведения и могут привести к потере данных.  
  Пример: `double → int`, `long → short`.  
  ```java
  double x = 123.456;
  int y = (int) x; // y = 123 (дробная часть потеряна).
  ```

**Потеря данных**  
Потеря возникает при сужающих преобразованиях:
- Усечение дробной части (при приведении к целому типу).
- Переполнение (если значение не помещается в целевой тип).  
  ```java
  byte z = (byte) 200; // z = -56 (из-за переполнения).
  ```

**Логический тип `boolean`**  
В Java `boolean` **не преобразуется** в другие типы и наоборот. Это отдельный тип, который может принимать только `true` или `false`.  
- **Ошибка компиляции** при попытке конвертировать `boolean` в `int` (или любой другой тип):  
  ```java
  boolean flag = true;
  // int num = flag; // Ошибка: несовместимые типы.
  // int num2 = (int) flag; // Ошибка: приведение невозможно.
  ```

**Итог**  
- Расширяющие преобразования безопасны, сужающие требуют явного приведения и могут терять данные.  
- `boolean` не конвертируется в другие типы данных (и наоборот).

---
---
### 20.	Какими значениями инициализируются переменные по умолчанию?
В Java переменные инициализируются значениями по умолчанию только если они являются **полями класса** (не локальными переменными!). Значения зависят от типа:

### 1. **Примитивные типы:**
- `byte` → `0`
- `short` → `0`
- `int` → `0`
- `long` → `0L`
- `float` → `0.0f`
- `double` → `0.0d`
- `char` → `'\u0000'` (символ с кодом 0)
- `boolean` → `false`

### 2. **Ссылочные типы (объекты, массивы и т.д.):**
- Любой объект → `null`

### Пример
```java
public class Example {
    // Поля класса инициализируются значениями по умолчанию
    int number;       // 0
    boolean flag;     // false
    String text;      // null
    double[] array;   // null

    public void method() {
        // Локальные переменные НЕ инициализируются автоматически!
        int localVar; // Ошибка компиляции, если не задать значение
    }
}
```

### Важно:
- **Локальные переменные** (в методах, конструкторах, блоках) **не получают значений по умолчанию** — их нужно явно инициализировать перед использованием.
- **Элементы массивов** всегда инициализируются значениями по умолчанию при создании массива (например, `new int[5]` заполнится нулями).

---
---
### 21.	Как передается значение переменной (по ссылке/значению)?
В Java **все переменные передаются по значению** (pass-by-value), но важно понимать, как это работает для разных типов данных:

---

### 1. **Примитивные типы (int, boolean, double и т.д.):**
- Передается **копия значения**.
- Изменения параметра внутри метода **не влияют** на исходную переменную.

**Пример:**
```java
public class Main {
    public static void main(String[] args) {
        int x = 10;
        modifyPrimitive(x);
        System.out.println(x); // 10 (значение не изменилось)
    }

    static void modifyPrimitive(int a) {
        a = 20; // меняется копия, исходная переменная x остаётся 10
    }
}
```

---

### 2. **Ссылочные типы (объекты, массивы):**
- Передается **копия ссылки** на объект (не сам объект!).
- Изменения **состояния объекта** внутри метода **отразятся** на исходном объекте (так как копия ссылки указывает на тот же объект).
- Если переназначить ссылку внутри метода (например, `obj = new Object()`), исходная ссылка **не изменится**.

**Пример:**
```java
public class Main {
    public static void main(String[] args) {
        Person person = new Person("Alice");
        modifyObject(person);
        System.out.println(person.getName()); // Bob (состояние объекта изменилось)
    }

    static void modifyObject(Person p) {
        p.setName("Bob"); // Изменение состояния объекта (влияет на исходный объект)
        p = new Person("Charlie"); // Переназначение ссылки (не влияет на исходную переменную)
    }
}

class Person {
    private String name;
    public Person(String name) { this.name = name; }
    public void setName(String name) { this.name = name; }
    public String getName() { return name; }
}
```

---

### Ключевые моменты:
- **Примитивы:** Передается копия значения → изменения внутри метода **не сохраняются**.
- **Объекты:** Передается копия ссылки → изменения **состояния объекта** сохраняются, но **переназначение ссылки** внутри метода не влияет на исходную переменную.
- **Java строго следует передаче по значению** (pass-by-value). Передачи по ссылке (pass-by-reference) в Java нет.

---

### Почему возникает путаница?
- Для объектов кажется, что передача происходит по ссылке, потому что изменения состояния объекта видны снаружи. Но это работает только из-за того, что копия ссылки указывает на тот же объект. Сама ссылка (переменная) не меняется.

**Пример с массивом:**
```java
public static void main(String[] args) {
    int[] arr = {1, 2, 3};
    modifyArray(arr);
    System.out.println(Arrays.toString(arr)); // [1, 99, 3]
}

static void modifyArray(int[] a) {
    a[1] = 99; // Изменение элемента массива (влияет на исходный массив)
    a = new int[]{10, 20}; // Переназначение ссылки (не влияет на исходный массив)
}
```

---
---
### 22.	Что вы знаете про классы обертки


---
---
### 23.	Определение коллекции


---
---
### 24.	Преимущества использования коллекций


---
---
### 25.	Какие объекты можно хранить в коллекциях


---
---
### 26.	Иерархия коллекций


---
---
### 27.	Отличия вектора от ArrayList


---
---
### 28.	Что знаете об коллекциях типа List как доб. элемент\расширяется коллекция


---
---
### 29.	Что знаете об коллекциях типа Set


---
---
### 30.	Что знаете об коллекциях типа Queue


---
---
### 31.	Что знаете об коллекциях типа Map и их принципиальное отличие


---
---
### 32.	Назовите основные реализации List,Set,Map


---
---
### 33.	Что общего у ArrayList\LinkedList, когда какой лучше использовать


---
---
### 34.	Расскажите про HashSet


---
---
### 35.	Расскажите про TreeSet/ Как сортируются элементы


---
---
### 36.	Как задается порядок следования объектов в коллекции, как отсортировать коллекцию


---
---
### 37.	Iterator. Как его получить(). Его методы что зачем


---
---
### 38.	Iterable что за зверь. Что за контракт описывает


---
---
### 39.	Коллекция 10 элементов.Вызываю 9x Iterator.hasNext а затем Iterator.next.Что вернется


---
---
### 40.	Как перебрать все ключи значения Map (Можно ли через Iterable)


---
---
### 41.	Разница Iterator,Enumerator,ListIterator


---
---
### 42.	В каких случаях может быть выброшено ConcurrentModificationException
